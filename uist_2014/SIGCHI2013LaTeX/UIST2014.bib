
@inproceedings{willis_printed_2012,
	address = {New York, {NY}, {USA}},
	series = {{UIST} '12},
	title = {Printed Optics: {3D} Printing of Embedded Optical Elements for Interactive Devices},
	isbn = {978-1-4503-1580-7},
	shorttitle = {Printed Optics},
	url = {http://doi.acm.org/10.1145/2380116.2380190},
	doi = {10.1145/2380116.2380190},
	abstract = {We present an approach to {3D} printing custom optical elements for interactive devices labelled Printed Optics. Printed Optics enable sensing, display, and illumination elements to be directly embedded in the casing or mechanical structure of an interactive device. Using these elements, unique display surfaces, novel illumination techniques, custom optical sensors, and embedded optoelectronic components can be digitally fabricated for rapid, high fidelity, highly customized interactive devices. Printed Optics is part of our long term vision for interactive devices that are {3D} printed in their entirety. In this paper we explore the possibilities for this vision afforded by fabrication of custom optical elements using today's {3D} printing technology.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the 25th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {{ACM}},
	author = {Willis, Karl and Brockmeyer, Eric and Hudson, Scott and Poupyrev, Ivan},
	year = {2012},
	keywords = {3d printing, additive manufacturing, display, light, optics, projection, rapid prototyping, sensing},
	pages = {589–598}
},

@inproceedings{brockmeyer_papillon:_2013,
	address = {New York, {NY}, {USA}},
	series = {{UIST} '13},
	title = {{PAPILLON:} Designing Curved Display Surfaces with Printed Optics},
	isbn = {978-1-4503-2268-3},
	shorttitle = {{PAPILLON}},
	url = {http://doi.acm.org/10.1145/2501988.2502027},
	doi = {10.1145/2501988.2502027},
	abstract = {We present a technology for designing curved display surfaces that can both display information and sense two dimensions of human touch. It is based on {3D} printed optics, where the surface of the display is constructed as a bundle of printed light pipes, that direct images from an arbitrary planar image source to the surface of the display. This effectively decouples the display surface and image source, allowing to iterate the design of displays without requiring changes to the complex electronics and optics of the device. In addition, the same optical elements also direct light from the surface of the display back to the image sensor allowing for touch input and proximity detection of a hand relative to the display surface. The resulting technology is effective in designing compact, efficient displays of a small size; this has been applied in the design of interactive animated eyes.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the 26th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {{ACM}},
	author = {Brockmeyer, Eric and Poupyrev, Ivan and Hudson, Scott},
	year = {2013},
	keywords = {3d printing, alternative displays, fabrication, finger input, gestures, interactive characters, organic user interfaces, touch sensing},
	pages = {457–462}
},

@article{cali_3d-printing_2012,
	title = {{3D-printing} of Non-assembly, Articulated Models},
	volume = {31},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/2366145.2366149},
	doi = {10.1145/2366145.2366149},
	abstract = {Additive manufacturing ({3D} printing) is commonly used to produce physical models for a wide variety of applications, from archaeology to design. While static models are directly supported, it is desirable to also be able to print models with functional articulations, such as a hand with joints and knuckles, without the need for manual assembly of joint components. Apart from having to address limitations inherent to the printing process, this poses a particular challenge for articulated models that should be posable: to allow the model to hold a pose, joints need to exhibit internal friction to withstand gravity, without their parts fusing during {3D} printing. This has not been possible with previous printable joint designs. In this paper, we propose a method for converting {3D} models into printable, functional, non-assembly models with internal friction. To this end, we have designed an intuitive work-flow that takes an appropriately rigged {3D} model, automatically fits novel {3D-printable} and posable joints, and provides an interface for specifying rotational constraints. We show a number of results for different articulated models, demonstrating the effectiveness of our method.},
	number = {6},
	urldate = {2014-01-02},
	journal = {{ACM} Trans. Graph.},
	author = {Calì, Jacques and Calian, Dan A. and Amati, Cristina and Kleinberger, Rebecca and Steed, Anthony and Kautz, Jan and Weyrich, Tim},
	month = nov,
	year = {2012},
	keywords = {3d printing, articulated models, mechanical joints},
	pages = {130:1–130:8}
},

@article{skouras_computational_2013,
	title = {Computational Design of Actuated Deformable Characters},
	volume = {32},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/2461912.2461979},
	doi = {10.1145/2461912.2461979},
	abstract = {We present a method for fabrication-oriented design of actuated deformable characters that allows a user to automatically create physical replicas of digitally designed characters using rapid manufacturing technologies. Given a deformable character and a set of target poses as input, our method computes a small set of actuators along with their locations on the surface and optimizes the internal material distribution such that the resulting character exhibits the desired deformation behavior. We approach this problem with a dedicated algorithm that combines finite-element analysis, sparse regularization, and constrained optimization. We validate our pipeline on a set of two- and three-dimensional example characters and present results in simulation and physically-fabricated prototypes.},
	number = {4},
	urldate = {2014-01-02},
	journal = {{ACM} Trans. Graph.},
	author = {Skouras, Mélina and Thomaszewski, Bernhard and Coros, Stelian and Bickel, Bernd and Gross, Markus},
	month = jul,
	year = {2013},
	keywords = {computational materials, control, elastic solids, physically-based simulation},
	pages = {82:1–82:10}
},

@article{coros_computational_2013,
	title = {Computational Design of Mechanical Characters},
	volume = {32},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/2461912.2461953},
	doi = {10.1145/2461912.2461953},
	abstract = {We present an interactive design system that allows non-expert users to create animated mechanical characters. Given an articulated character as input, the user iteratively creates an animation by sketching motion curves indicating how different parts of the character should move. For each motion curve, our framework creates an optimized mechanism that reproduces it as closely as possible. The resulting mechanisms are attached to the character and then connected to each other using gear trains, which are created in a semi-automated fashion. The mechanical assemblies generated with our system can be driven with a single input driver, such as a hand-operated crank or an electric motor, and they can be fabricated using rapid prototyping devices. We demonstrate the versatility of our approach by designing a wide range of mechanical characters, several of which we manufactured using {3D} printing. While our pipeline is designed for characters driven by planar mechanisms, significant parts of it extend directly to non-planar mechanisms, allowing us to create characters with compelling {3D} motions.},
	number = {4},
	urldate = {2014-01-02},
	journal = {{ACM} Trans. Graph.},
	author = {Coros, Stelian and Thomaszewski, Bernhard and Noris, Gioacchino and Sueda, Shinjiro and Forberg, Moira and Sumner, Robert W. and Matusik, Wojciech and Bickel, Bernd},
	month = jul,
	year = {2013},
	keywords = {Animation, fabrication, interactive design, mechanical characters},
	pages = {83:1–83:12}
},

@article{goodrich_human-robot_2007,
	title = {Human-robot Interaction: A Survey},
	volume = {1},
	issn = {1551-3955},
	shorttitle = {Human-robot Interaction},
	url = {http://dx.doi.org/10.1561/1100000005},
	doi = {10.1561/1100000005},
	abstract = {Human-Robot Interaction ({HRI)} has recently received considerable attention in the academic community, in labs, in technology companies, and through the media. Because of this attention, it is desirable to present a survey of {HRI} to serve as a tutorial to people outside the field and to promote discussion of a unified vision of {HRI} within the field. The goal of this review is to present a unified treatment of {HRI-related} problems, to identify key themes, and discuss challenge problems that are likely to shape the field in the near future. Although the review follows a survey structure, the goal of presenting a coherent "story" of {HRI} means that there are necessarily some well-written, intriguing, and influential papers that are not referenced. Instead of trying to survey every paper, we describe the {HRI} story from multiple perspectives with an eye toward identifying themes that cross applications. The survey attempts to include papers that represent a fair cross section of the universities, government efforts, industry labs, and countries that contribute to {HRI}, and a cross section of the disciplines that contribute to the field, such as human, factors, robotics, cognitive psychology, and design.},
	number = {3},
	urldate = {2014-01-02},
	journal = {Found. Trends Hum.-Comput. Interact.},
	author = {Goodrich, Michael A. and Schultz, Alan C.},
	month = jan,
	year = {2007},
	pages = {203–275}
},

@article{sheridan_human-automation_2005,
	title = {Human-Automation Interaction},
	volume = {1},
	issn = {1557-{234X},},
	url = {http://rev.sagepub.com/content/1/1/89},
	doi = {10.1518/155723405783703082},
	abstract = {Automation does not mean humans are replaced; quite the opposite. Increasingly, humans are asked to interact with automation in complex and typically large-scale systems, including aircraft and air traffic control, nuclear power, manufacturing plants, military systems, homes, and hospitals. This is not an easy or error-free task for either the system designer or the human operator/automation supervisor, especially as computer technology becomes ever more sophisticated. This review outlines recent research and challenges in the area, including taxonomies and qualitative models of human-automation interaction; descriptions of automation-related accidents and studies of adaptive automation; and social, political, and ethical issues.},
	language = {en},
	number = {1},
	urldate = {2014-01-02},
	journal = {Reviews of Human Factors and Ergonomics},
	author = {Sheridan, Thomas B. and Parasuraman, Raja},
	month = jun,
	year = {2005},
	pages = {89--129}
},

@inproceedings{pacchierotti_evaluation_2006,
	title = {Evaluation of Passing Distance for Social Robots},
	doi = {10.1109/ROMAN.2006.314436},
	abstract = {Casual encounters with mobile robots for nonexperts can be a challenge due to lack of an interaction model. The present work is based on the rules from proxemics which are used to design a passing strategy. In narrow corridors the lateral distance of passage is a key parameter to consider. An implemented system has been used in a small study to verify the basic parametric design for such a system. In total 10 subjects evaluated variations in proxemics for encounters with a robot in a corridor setting. The user feedback indicates that entering the intimate sphere of people is less comfortable, however a too significant avoidance is also considered unnecessary. Adequate signaling of avoidance is a behaviour that must be carefully tuned},
	booktitle = {The 15th {IEEE} International Symposium on Robot and Human Interactive Communication, 2006. {ROMAN} 2006},
	author = {Pacchierotti, E. and Christensen, {H.I.} and Jensfelt, P.},
	year = {2006},
	keywords = {Cleaning, Feedback, Human robot interaction, Logistics, Mobile communication, Orbital robotics, Postal services, Production facilities, Transportation, interaction model, man-machine systems, mobile robots, passing distance evaluation, proxemics, social robots, user feedback},
	pages = {315--320}
},

@inproceedings{gockley_natural_2007,
	address = {New York, {NY}, {USA}},
	series = {{HRI} '07},
	title = {Natural Person-following Behavior for Social Robots},
	isbn = {978-1-59593-617-2},
	url = {http://doi.acm.org/10.1145/1228716.1228720},
	doi = {10.1145/1228716.1228720},
	abstract = {We are developing robots with socially appropriate spatial skills not only to travel around or near people, but also to accompany people side-by-side. As a step toward this goal, we are investigating the social perceptions of a robot's movement as it follows behind a person. This paper discusses our laser-based person-tracking method and two different approaches to person-following: direction-following and path-following. While both algorithms have similar characteristics in terms of tracking performance and following distances, participants in a pilot study rated the direction-following behavior as significantly more human-like and natural than the path-following behavior. We argue that the path-following method may still be more appropriate in some situations, and we propose that the ideal person-following behavior may be a hybrid approach, with the robot automatically selecting which method to use.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the {ACM/IEEE} International Conference on Human-robot Interaction},
	publisher = {{ACM}},
	author = {Gockley, Rachel and Forlizzi, Jodi and Simmons, Reid},
	year = {2007},
	keywords = {human-robot interaction, person following, person tracking, social robots},
	pages = {17–24}
},

@inproceedings{yamaoka_lifelike_2005,
	title = {{"Lifelike"} behavior of communication robots based on developmental psychology findings},
	doi = {10.1109/ICHR.2005.1573601},
	abstract = {Researchers in developmental psychology have reported various findings about animate-inanimate distinctions, especially the decision criteria of human infants categorizing animate existence, such as distinguishing animals and humans from the inanimate. The purpose of our research is to develop animate or "lifelike" behavior for humanoid robots based on such categorizing, which would be expected to potentially make human-robot interaction more natural. Our approach is unique because we focus on the robot's mechanism and behavior design using environmental sensors. Consequently, we use a motion capturing system, which enables us to leapfrog technological developments for the robots' sensing abilities. The robot that we have developed reacts to human behavior, and it is implemented in order to satisfy the features of animate existence according to developmental psychology. Two experiments were conducted to verify its effects. The results of the first experiment verified the effectiveness of lifelike behavior and also showed that random behavior, which partly satisfies the features of animate existence, received a halfway evaluation for lifelikeness. The second experiment demonstrated the effectiveness of the developed robot for investigating the effect of a robot's cognitive ability for human-robot interaction},
	booktitle = {2005 5th {IEEE-RAS} International Conference on Humanoid Robots},
	author = {Yamaoka, F. and Kanda, T. and Ishiguro, H. and Hagita, N.},
	year = {2005},
	keywords = {Animals, Animation, Cognitive robotics, Human robot interaction, Intelligent robots, Laboratories, Pediatrics, Psychology, Robot sensing systems, artificial intelligence, cognitive ability, communication robots, developmental psychology findings, human-robot interaction, humanoid robots, man-machine systems, motion capturing system},
	pages = {406--411}
},

@inproceedings{breazeal_public_2002,
	address = {New York, {NY}, {USA}},
	series = {{SIGGRAPH} '02},
	title = {Public Anemone: An Organic Robot Creature},
	isbn = {1-58113-525-4},
	shorttitle = {Public Anemone},
	url = {http://doi.acm.org/10.1145/1242073.1242111},
	doi = {10.1145/1242073.1242111},
	abstract = {We have created an articulated robotic creature and situated it within an interactive terrarium to explore the aesthetic, expressive, and interactive qualities that give robots an organic and engaging presence to people.},
	urldate = {2014-01-02},
	booktitle = {{ACM} {SIGGRAPH} 2002 Conference Abstracts and Applications},
	publisher = {{ACM}},
	author = {Breazeal, Cynthia and Brooks, Andrew and Hancher, Matt and Strickon, Josh and Kidd, Cory and {McBean}, John and Stiehl, Dan},
	year = {2002},
	keywords = {autonomous robotics, interactive characters, organic robotics},
	pages = {76–76}
},

@inproceedings{lee_autonomous_2007,
	address = {New York, {NY}, {USA}},
	series = {{HRI} '07},
	title = {Autonomous Behavior Design for Robotic Appliance},
	isbn = {978-1-59593-617-2},
	url = {http://doi.acm.org/10.1145/1228716.1228744},
	doi = {10.1145/1228716.1228744},
	abstract = {We consider robotic appliances, mobile and intelligent robots that perform household tasks, and study design method for autonomous behaviors of robotic appliances, a key component in human-robot and robot-environment interactions. Specifically, we develop robot behavior diagram, a visualized, robot-centric, chart-based behavior design method that is useful in describing robotic behaviors and transitions among them. This tool enables systematic construction of exhaustive set of autonomous behaviors, within the context of given set of robotic functionalities. First, the set of functionalities for a given robot is defined. Then, employing the defined functionalities, a diagram is constructed with behavioral states and events that can trigger transitions to other behaviors. For any given behavioral state, all plausible events are considered, and this is repeated until the diagram is complete with all the possible behaviors and events. We demonstrate that, via this method, a complete and robust behavioral scenario design is indeed attainable, by applying robot behavior diagram approach to an example household cleaning robot platform.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the {ACM/IEEE} International Conference on Human-robot Interaction},
	publisher = {{ACM}},
	author = {Lee, Hyunjeong and Kim, Hyun Jin and Kim, Changsu},
	year = {2007},
	keywords = {behavior design, domestic robots, human-robot interaction, interaction design, robot appliance, service robots},
	pages = {201–208}
},

@misc{_approachability:_????,
	title = {Approachability: How People Interpret Automatic Door Movement as Gesture},
	shorttitle = {Approachability},
	url = {http://www.ijdesign.org/ojs/index.php/IJDesign/article/view/574},
	abstract = {International Journal of Design, {IJDesign}, {IJD}, {SCI}, {SSCI}, {A\&HCI}, Automatic doors exemplify the challenges of designing emotionally welcoming interactive systems—a critical issue in the design of any system of incidental use. We attempt to broaden the automatic door’s repertoire of signals by examining how people respond to a variety of “door gestures” designed to offer different levels of approachability. In a pilot study, participants ({\textless}em{\textgreater}N{\textless}/em{\textgreater}=48) who walked past a physical gesturing door were asked to fill out a questionnaire about that experience. In our follow-up study, participants ({\textless}em{\textgreater}N{\textless}/em{\textgreater}=51) viewed 12 video clips depicting a person walking toward and past an automatic door that moved with different speeds and trajectories. In both studies, our Likert-scale measures and open-ended responses indicated significant uniformity in participants’ interpretation of the behaviour of the door prototypes. The participants saw these motions as gestures with human-like characteristics such as cognition and intent. Our work suggests that even in non-anthropomorphic objects, gestural motions can convey a sense of approachability.},
	urldate = {2014-01-02},
	journal = {International Journal of Dsign},
	keywords = {{A\&HCI}, {IJD}, {IJDesign}, International Journal of Design, {SCI}, {SSCI}}
},

@inproceedings{makinen_experiences_2002,
	address = {New York, {NY}, {USA}},
	series = {{NordiCHI} '02},
	title = {Experiences on a Multimodal Information Kiosk with an Interactive Agent},
	isbn = {1-58113-616-1},
	url = {http://doi.acm.org/10.1145/572020.572064},
	doi = {10.1145/572020.572064},
	abstract = {Information kiosks provide useful information to many people in many different situations and they should be easy to use since persons with little or no knowledge of computing may use them. One way to ease interaction between a user and a kiosk is multimodal interaction. In this paper, we present a multimodal kiosk that includes a computer vision component and an interactive agent that makes use of computer vision. We also discuss preliminary results of user tests that were carried out with the kiosk.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the Second Nordic Conference on Human-computer Interaction},
	publisher = {{ACM}},
	author = {Mäkinen, Erno and Patomäki, Saija and Raisamo, Roope},
	year = {2002},
	keywords = {computer vision, human-computer interaction, interactive agent, multimodal information kiosk},
	pages = {275–278}
},

@inproceedings{walter_strikeapose:_2013,
	address = {New York, {NY}, {USA}},
	series = {{CHI} '13},
	title = {{StrikeAPose:} Revealing Mid-air Gestures on Public Displays},
	isbn = {978-1-4503-1899-0},
	shorttitle = {{StrikeAPose}},
	url = {http://doi.acm.org/10.1145/2470654.2470774},
	doi = {10.1145/2470654.2470774},
	abstract = {We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56\%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users' variations.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Walter, Robert and Bailly, Gilles and Müller, Jörg},
	year = {2013},
	keywords = {field study, initial gesture, public displays, revelation},
	pages = {841–850}
},

@inproceedings{gockley_designing_2005,
	title = {Designing robots for long-term social interaction},
	doi = {10.1109/IROS.2005.1545303},
	abstract = {Valerie the roboceptionist is the most recent addition to Carnegie Mellon's social robots project. A permanent installation in the entranceway to Newell-Simon hall, the robot combines useful functionality - giving directions, looking up weather forecasts, etc. - with an interesting and compelling character. We are using Valerie to investigate human-robot social interaction, especially long-term human-robot "relationships". Over a nine-month period, we have found that many visitors continue to interact with the robot on a daily basis, but that few of the individual interactions last for more than 30 seconds. Our analysis of the data has indicated several design decisions that should facilitate more natural human-robot interactions.},
	booktitle = {2005 {IEEE/RSJ} International Conference on Intelligent Robots and Systems, 2005. ({IROS} 2005)},
	author = {Gockley, R. and Bruce, A. and Forlizzi, J. and Michalowski, M. and Mundell, A. and Rosenthal, S. and Sellner, B. and Simmons, R. and Snipes, K. and Schultz, {A.C.} and Wang, Jue},
	year = {2005},
	keywords = {Buildings, Data analysis, Displays, Face, Facial animation, Human robot interaction, Laboratories, Monitoring, Weather forecasting, human computer interaction, human-robot interaction, human-robot social interaction, legged locomotion, long-term human-robot relationship, long-term social interaction, mobile robots, roboceptionist, robot design, robotics, social robot, social robots},
	pages = {1338--1343}
},

@inproceedings{paulos_urban_2005,
	title = {Urban probes: Encountering our emerging urban atmospheres},
	shorttitle = {Urban probes},
	abstract = {Urban Atmospheres captures a unique, synergistic moment – expanding urban populations, rapid adoption of Bluetooth mobile devices, tiny ad hoc sensor networks, and the widespread influence of wireless technologies across our growing urban landscapes. The United Nations recently reported that 48 percent of the world's population current live in urban areas and that this number is expected to exceed the 50 percent mark world wide by 2007 [1]. In developed nations the number of urban dwellers is even more dramatic – expected to exceed 75\%. Current studies project Bluetooth-enabled devices to reach 5.4 billion units by 2005 – five times the number of mobile phones or Internet connections [2]. Mobile phone penetration already exceeds 80 \% of the population in places like the European Union ({EU)} and parts of Asia [3]. {WiFi} hardware is being deployed at the astonishing rate of one every 4 seconds globally [4]. We argue that now is the time to initiate inspirational research into the very essence of these newly emerging technological urban spaces. We desire to move towards an improved understanding of the emotional experience of urban life. This paper describes Urban Probes – a lightweight, provocative, intervention methodology designed to rapidly deconstruct urban situations, reveal new opportunities for technology in urban spaces, and guide future long term research in urban computing. We also describe a completed Urban Probe exploring urban trash.},
	booktitle = {{CHI}},
	publisher = {{ACM} Press},
	author = {Paulos, Eric},
	year = {2005},
	pages = {341–350}
},

@inproceedings{brignull_enticing_2003,
	title = {Enticing people to interact with large public displays in public spaces},
	abstract = {Abstract: Large displays are increasingly being placed in public places to support community and social activities. However, a major problem that has been observed with this new form of public interaction is the resistance by the public to participate. A main reason is due to the prominence of the affective aspect of the user experience. In particular, feelings of social embarrassment often act as a barrier. Our paper is concerned with understanding why this is the case and considering how we can attempt to overcome these aspects through improving the design of public interaction. Our focus is on how groups of people socialize around large public displays, the way they move towards them, congregate around them and change from being onlookers to participants and back again. We describe a system – the Opinionizer – which we designed and placed in two authentic social gatherings, intended to encourage socializing and interaction. We present our findings in terms of the patterns of physical and social engagement that take place around it. We then present a model of public interaction flow, which we use as the basis from which to provide design recommendations for encouraging public participation.},
	booktitle = {In Proceedings of the {IFIP} International Conference on Human-Computer Interaction ({INTERACT} 2003},
	author = {Brignull, Harry and Rogers, Yvonne},
	year = {2003},
	pages = {17–24}
},

@incollection{huang_overcoming_2008,
	series = {Lecture Notes in Computer Science},
	title = {Overcoming Assumptions and Uncovering Practices: When Does the Public Really Look at Public Displays?},
	copyright = {©2008 Springer Berlin Heidelberg},
	isbn = {978-3-540-79575-9, 978-3-540-79576-6},
	shorttitle = {Overcoming Assumptions and Uncovering Practices},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-79576-6_14},
	abstract = {This work reports on the findings of a field study examining the current use practices of large ambient information displays in public settings. Such displays are often assumed to be inherently eye-catching and appealing to people nearby, but our research shows that glancing and attention at large displays is complex and dependent on many factors. By understanding how such displays are being used in current, public, non-research settings and the factors that impact usage, we offer concrete, ecologically valid knowledge and design implications about these technologies to researchers and designers who are employing large ambient displays in their work.},
	number = {5013},
	urldate = {2014-01-02},
	booktitle = {Pervasive Computing},
	publisher = {Springer Berlin Heidelberg},
	author = {Huang, Elaine M. and Koster, Anna and Borchers, Jan},
	editor = {Indulska, Jadwiga and Patterson, Donald J. and Rodden, Tom and Ott, Max},
	month = jan,
	year = {2008},
	keywords = {Computer Communication Networks, Computers and Society, Information Storage and Retrieval, Information Systems Applications ({incl.Internet)}, Large displays, Special Purpose and Application-Based Systems, Systems and Data Security, ambient displays, public settings, qualitative studies},
	pages = {228--243}
},

@article{somanath_spidey:_2012,
	title = {Spidey: a Robotic Tabletop Assistant},
	shorttitle = {Spidey},
	url = {http://dspace.ucalgary.ca/jspui/handle/1880/48908},
	abstract = {This paper presents our efforts of exploring the possibilities of 
combining tabletop robots and assistant robots. Our paper 
presents the design and prototyping of Spidey, a robotic assistant 
on a tabletop environment which works together as a team 
member with its human companions, aware of their tabletop 
actions and reacting or initiating tabletop actions according to the 
task requirements. Spidey is designed both as a proof of concept, 
suggesting the benefits, and reflecting on the limitations of a 
robotic assistant in an interactive reservoir engineering tabletop 
visualization application we are implementing. This paper 
motivates our concept of a robotic tabletop assistant, and outlines 
our design efforts and the current Spidey prototype},
	language = {eng},
	urldate = {2014-01-02},
	author = {Somanath, Sowmya and Sharlin, Ehud and Costa Sousa, Mario},
	month = feb,
	year = {2012},
	note = {No},
	keywords = {{HRI}, Robots, tabletop robots}
},

@inproceedings{somanath_integrating_2013,
	title = {Integrating a robot in a tabletop reservoir engineering application},
	doi = {10.1109/HRI.2013.6483585},
	abstract = {We present our work-in-progress efforts of designing a simple tabletop robotic assistant that supports users as they interact with tabletop reservoir visualization application. Our prototype, Spidey, is designed to assist reservoir engineers in performing simple data exploration tasks on the interactive tabletop. We present our design as well as preliminary findings from a study of Spidey involving both interaction designers and reservoir engineers.},
	booktitle = {2013 8th {ACM/IEEE} International Conference on Human-Robot Interaction ({HRI)}},
	author = {Somanath, S. and Sharlin, E. and Sousa, {M.C.}},
	year = {2013},
	keywords = {Fingers, Prototypes, Robots, Spidey, Visualization, collaboration, data exploration task, data visualisation, geotechnical engineering, human-robot interaction, interaction design, interactive systems, interactive tabletop, legged locomotion, reservoir engineer assistance, reservoirs, robotic assistants, social robots, tabletop interaction, tabletop reservoir engineering application, tabletop reservoir visualization application, tabletop robotic assistant, tabletop robots},
	pages = {229--230}
},

@inproceedings{pedersen_tangible_2011,
	address = {New York, {NY}, {USA}},
	series = {{CHI} '11},
	title = {Tangible Bots: Interaction with Active Tangibles in Tabletop Interfaces},
	isbn = {978-1-4503-0228-9},
	shorttitle = {Tangible Bots},
	url = {http://doi.acm.org/10.1145/1978942.1979384},
	doi = {10.1145/1978942.1979384},
	abstract = {We present interaction techniques for tangible tabletop interfaces that use active, motorized tangibles, what we call Tangible Bots. Tangible Bots can reflect changes in the digital model and assist users by haptic feedback, by correcting errors, by multi-touch control, and by allowing efficient interaction with multiple tangibles. A first study shows that Tangible Bots are usable for fine-grained manipulation (e.g., rotating tangibles to a particular orientation); for coarse movements, Tangible Bots become useful only when several tangibles are controlled simultaneously. Participants prefer Tangible Bots and find them less taxing than passive, non-motorized tangibles. A second study focuses on usefulness by studying how electronic musicians use Tangible Bots to create music with a tangible tabletop application. We conclude by discussing the further potential of active tangibles, and their relative benefits over passive tangibles and multi-touch.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Pedersen, Esben Warming and Hornbæk, Kasper},
	year = {2011},
	keywords = {active tangibles, bidirectional interfaces, tangible user interfaces, user evaluation},
	pages = {2975–2984}
},

@inproceedings{sultanum_touching_2010,
	address = {New York, {NY}, {USA}},
	series = {{ITS} '10},
	title = {Touching the Depths: Introducing Tabletop Interaction to Reservoir Engineering},
	isbn = {978-1-4503-0399-6},
	shorttitle = {Touching the Depths},
	url = {http://doi.acm.org/10.1145/1936652.1936671},
	doi = {10.1145/1936652.1936671},
	abstract = {Modern reservoir engineering is dependent on {3D} visualization tools. However, as we argue in this paper, the current tools used in this domain are not completely aligned with the reservoir engineer's interactive needs, and do not address fundamental user issues, such as collaboration. We base our work on a set of observations of reservoir engineers, and their unique interactive tasks and needs. We present insightful knowledge of the domain, and follow with a prototype for an interactive reservoir visualization system, on the Microsoft Surface. We conclude by presenting a design critique we performed using our prototype, and reflecting on the impact we believe tabletop interaction will have on the domain of reservoir engineering.},
	urldate = {2014-01-02},
	booktitle = {{ACM} International Conference on Interactive Tabletops and Surfaces},
	publisher = {{ACM}},
	author = {Sultanum, Nicole and Sharlin, Ehud and Sousa, Mario Costa and Miranda-Filho, Daniel N. and Eastick, Rob},
	year = {2010},
	keywords = {collaboration, reservoir engineering, tabletop, tangible user interface, visualization system},
	pages = {105–108}
},

@inproceedings{Houben:2013:OIB:2468356.2468631,
 author = {Houben, Steven and Weichel, Christian},
 title = {Overcoming Interaction Blindness Through Curiosity Objects},
 booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '13},
 year = {2013},
 isbn = {978-1-4503-1952-2},
 location = {Paris, France},
 pages = {1539--1544},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2468356.2468631},
 doi = {10.1145/2468356.2468631},
 acmid = {2468631},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {curiosity object, display blindness, interaction blindness, situated public displays},
}, 


@incollection{ju_animate_2010,
	series = {Lecture Notes in Computer Science},
	title = {Animate Objects: How Physical Motion Encourages Public Interaction},
	copyright = {©2010 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-13225-4, 978-3-642-13226-1},
	shorttitle = {Animate Objects},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-13226-1_6},
	abstract = {The primary challenge for information terminals, kiosks, and incidental use systems of all sorts, is that of getting the “first click” from busy passersby. This paper presents two studies that investigate the role of motion and physicality in drawing people to look and actively interact with generic information kiosks. The first study was designed as a 2x2 factorial design, physical v. on-screen gesturing and hand v. arrow motion, on a kiosk deployed in two locations, a bookstore and a computer science building lobby. The second study examined the effect of physical v. projected gesturing, and included a follow-up survey. Over twice as many passersby interacted in the physical v. on-screen condition in the first study and 60\% more interacted in the second. These studies, in concert, indicate that physical gesturing does indeed significantly attract more looks and use for the information kiosk, and that form affects people’s impression and interpretation of these gestures.},
	number = {6137},
	urldate = {2014-01-02},
	booktitle = {Persuasive Technology},
	publisher = {Springer Berlin Heidelberg},
	author = {Ju, Wendy and Sirkin, David},
	editor = {Ploug, Thomas and Hasle, Per and Oinas-Kukkonen, Harri},
	month = jan,
	year = {2010},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Appl. in Social and Behavioral Sciences, Computers and Education, Information Storage and Retrieval, Information Systems Applications ({incl.Internet)}, User Interfaces and Human Computer Interaction, field study, gesturing, kiosk, physicality, public},
	pages = {40--51}
},

@inproceedings{christian_speak_2000,
	address = {New York, {NY}, {USA}},
	series = {{CHI} '00},
	title = {Speak out and Annoy Someone: Experience with Intelligent Kiosks},
	isbn = {1-58113-216-6},
	shorttitle = {Speak out and Annoy Someone},
	url = {http://doi.acm.org/10.1145/332040.332449},
	doi = {10.1145/332040.332449},
	abstract = {An intelligent kiosk is a public information kiosk that senses the presence of humans and communicates in a natural way. To examine issues of human-kiosk interaction, we have built and deployed two versions of intelligent kiosks. The first kiosk design combines machine vision to locate and track people in the vicinity with an animated talking head that focuses on clients and talks to them. The second kiosk design uses infrared and sonar sensors to sense clients and multiple interacting agents to communicate with the client.
The foremost lessons learned from public trials include (1) people are attracted to an animated face that watches them, (2) small mobile agents interact better with kiosk content than a single fixed face, (3) speaker-independent speech recognition is only useful in targeted applications, and (4) the quality of the content on the kiosk strongly influences the client's evaluation of the quality of the technology.},
	urldate = {2014-01-02},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Christian, Andrew D. and Avery, Brian L.},
	year = {2000},
	keywords = {information display, machine vision, public kiosk, speech recognition, talking avatar, user interface design},
	pages = {313–320}
}